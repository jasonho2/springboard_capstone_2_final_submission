{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jho\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# read all individual text reviews to a list of lists then convert to a dataframe\n",
    "\n",
    "# location of folder with reviews\n",
    "filepath = 'C:/Users/jho/Desktop/data_science/op_spam_v1.4'\n",
    "# empty list\n",
    "list_reviews = []\n",
    "\n",
    "# first level\n",
    "negative_or_positive = 'negative_polarity'\n",
    "\n",
    "# 1600 to unpack (1 folder)\n",
    "for polarity in os.listdir(filepath):\n",
    "    # second level\n",
    "    deceptive_or_truthful = 'deceptive_from_MTurk'\n",
    "    # 800 to unpack (2 folders)\n",
    "    for classification in os.listdir(filepath+'/{}'.format(negative_or_positive)):\n",
    "        i = 1\n",
    "        # 400 to unpack (4 folders, or 2 in each subfolder) (third level)\n",
    "        for fold in os.listdir(filepath+'/{}'.format(negative_or_positive)+'/{}'.format(deceptive_or_truthful)):\n",
    "            #80 to unpack (there are 80 reviews in each fold, and there are 5 folds with each of the 4 subfolders) (fourth level)\n",
    "            for file in os.listdir(filepath+'/{}'.format(negative_or_positive)+'/{}'.format(deceptive_or_truthful)+'/fold{}'.format(i)):\n",
    "                # unpack and read (read each file as a review as you unpack all the folders)\n",
    "                with open(filepath+'/{}'.format(negative_or_positive)+'/{}'.format(deceptive_or_truthful)+'/fold{}/'.format(i)+file) as f:\n",
    "                    list_reviews.append([file, f.readline()])\n",
    "                    \n",
    "            i += 1\n",
    "        \n",
    "        # for the folders that have different names than deceptive_from_MTurk in the deceptive/truthful folders\n",
    "        if len(list_reviews) < 401:\n",
    "            deceptive_or_truthful = 'truthful_from_Web'\n",
    "        elif len(list_reviews) > 402:\n",
    "            deceptive_or_truthful = 'truthful_from_TripAdvisor'\n",
    "            \n",
    "    # change the folder for polarity\n",
    "    negative_or_positive = 'positive_polarity'\n",
    "    \n",
    "\n",
    "# create all_reviews_df for list_reviews\n",
    "all_reviews_df = pd.DataFrame(list_reviews, columns=['index', 'review'])\n",
    "\n",
    "\n",
    "# add columns for the classification to the all_reviews_df dataframe. 1 is deceptive/negative and 0 is truthful/positive\n",
    "all_reviews_df.insert(2, 'negative', np.nan)\n",
    "all_reviews_df.insert(3, 'deceptive', np.nan)\n",
    "\n",
    "#print(all_reviews_df)\n",
    "\n",
    "# counter i to iterate over all reviews in all_reviews_df\n",
    "for i in range(0, len(all_reviews_df)):\n",
    "    \n",
    "    # indices 0-799 are negative polarity\n",
    "    if i < 800:\n",
    "        all_reviews_df['negative'].loc[i] = '1'\n",
    "    else:\n",
    "        all_reviews_df['negative'].loc[i] = '0'\n",
    "        \n",
    "    # indices 400-799 are truthful\n",
    "    if 400 <= i < 800:\n",
    "        all_reviews_df['deceptive'].loc[i] = '0'\n",
    "    # indices 1200-1599 are truthful\n",
    "    elif i >= 1200:\n",
    "        all_reviews_df['deceptive'].loc[i] = '0'\n",
    "    # the rest are deceptive\n",
    "    else:\n",
    "        all_reviews_df['deceptive'].loc[i] = '1'\n",
    "        \n",
    "#print(all_reviews_df)\n",
    "\n",
    "# create a dataframe with only the reviews\n",
    "text_only = all_reviews_df['review']\n",
    "\n",
    "#print(text_only.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### for tfidf vectorizer ####\n",
    "\n",
    "# creates tfidf vector / matrix for X and the target y, using original tfidf vector\n",
    "\n",
    "def make_xy(all_reviews_df, tfidf=None):\n",
    "    #Your code here    \n",
    "    if tfidf is None:\n",
    "        tfidf = TfidfVectorizer(min_df=0, ngram_range=(1,2))\n",
    "    X = tfidf.fit_transform(all_reviews_df['review'])\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (all_reviews_df.deceptive == '1').values.astype(np.int)\n",
    "    return X, y, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 1.000000\n",
      "Accuracy on test data:     0.890000\n",
      "\n",
      "44\n",
      "\n",
      "356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TFIDF Vectorizer for MultinomialNB and Linear SVM\n",
    "\n",
    "# creates:  x_train: Xtfidf, y_train: ytfidf\n",
    "#           x_test: Xtfidf_test aka the transformed reviews located at the test_index locations, y_test = X_test labels\n",
    "\n",
    "# shuffle split the reviews and test on 400 reviews\n",
    "ss = ShuffleSplit(n_splits=1, test_size=0.25)\n",
    "\n",
    "# splitting the reviews and returning their index from the dataframe\n",
    "for train_index, test_index in ss.split(all_reviews_df['review']):\n",
    "    \n",
    "    #print(\"%s %s\" % (train_index, test_index))\n",
    "    #print(\"%s\" % (test_index))\n",
    "    \n",
    "    # create tfidf vectors from make_xy function using the training indices\n",
    "    Xtfidf, ytfidf, tfidf = make_xy(all_reviews_df.loc[train_index])\n",
    "    \n",
    "    # select classifier. choosing linear svc\n",
    "    clf = LinearSVC()\n",
    "    #clf = svm.SVC(kernel='linear')\n",
    "    #clf = MultinomialNB()\n",
    "    clf_fit = clf.fit(Xtfidf, ytfidf)\n",
    "    # transform the tfidf vector and use as x_test for predictions\n",
    "    Xtfidf_test = tfidf.transform(all_reviews_df['review'][test_index])\n",
    "    prediction = clf_fit.predict(Xtfidf_test)\n",
    "    \n",
    "    #print(prediction)\n",
    "    \n",
    "    #print(all_reviews_df['deceptive'][test_index])\n",
    "    #print(ytfidf[0])\n",
    "\n",
    "    # get the accuracy scores from training and testing sets\n",
    "    training_accuracy = clf.score(Xtfidf, ytfidf)\n",
    "    testing_accuracy = clf.score(Xtfidf_test, all_reviews_df['deceptive'][test_index].astype(np.int))\n",
    "\n",
    "    print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "    print(\"Accuracy on test data:     {:2f}\".format(testing_accuracy))\n",
    "    print('')\n",
    "    \n",
    "    ## this prints all of the incorrectly classified reviews\n",
    "\n",
    "    # empty list\n",
    "    wrong_predictions = []\n",
    "\n",
    "    # search where the predicted label is not the same as the label in all_reviews_df\n",
    "    for index in range(len(prediction)):\n",
    "        if all_reviews_df['deceptive'].astype(np.int)[test_index[index]] != prediction[index]:\n",
    "            wrong_predictions.append([all_reviews_df['index'].loc[test_index[index]], all_reviews_df['review'].loc[test_index[index]], all_reviews_df['deceptive'].loc[test_index[index]]])\n",
    "\n",
    "    # convert to dataframe\n",
    "    wrong_predictions = pd.DataFrame(wrong_predictions)\n",
    "    print(len(wrong_predictions))\n",
    "    print('')\n",
    "    \n",
    "    ## this prints all of the correctly classified reviews\n",
    "\n",
    "    # empty list\n",
    "    right_predictions = []\n",
    "\n",
    "    # search where the predicted label is not the same as the label in all_reviews_df\n",
    "    for index in range(len(prediction)):\n",
    "        if all_reviews_df['deceptive'].astype(np.int)[test_index[index]] == prediction[index]:\n",
    "            right_predictions.append([all_reviews_df['index'].loc[test_index[index]], all_reviews_df['review'].loc[test_index[index]], all_reviews_df['deceptive'].loc[test_index[index]]])\n",
    "\n",
    "    # convert to dataframe\n",
    "    right_predictions = pd.DataFrame(right_predictions)\n",
    "    print(len(right_predictions))\n",
    "    print('')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# truthful reviews classified as deceptive\n",
    "false_positives = wrong_predictions[wrong_predictions[2] == '0']\n",
    "#false_positives\n",
    "\n",
    "# deceptive reviews classified as deceptive\n",
    "true_positives = right_predictions[right_predictions[2] == '1']\n",
    "#true_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the true positive and false positive features from the same tfidf vector\n",
    "\n",
    "# use THE SAME tfidf vector (bi-grams) from make_xy to the true and false positives\n",
    "# the words have the same column indices for tp and fp\n",
    "\n",
    "# create the compressed sparse matrices for true and false positives\n",
    "csr_mat_tp = tfidf.transform(true_positives[1])\n",
    "csr_mat_fp = tfidf.transform(false_positives[1])\n",
    "\n",
    "# average importance for features\n",
    "tp_averages = csr_mat_tp.todense().mean(axis=0)\n",
    "fp_averages = csr_mat_fp.todense().mean(axis=0)\n",
    "\n",
    "# creates dict of all features from the tfidf vector, convert to list\n",
    "index_words = tfidf.vocabulary_\n",
    "index_words_list = list(index_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.016934888571398698, 'neighborhood')\n",
      "(0.015952437608524717, 'we')\n",
      "(0.015022161677194676, 'nicer hotel')\n",
      "(0.014649130457456987, 'what can')\n",
      "(0.014503761681617076, 'bottle')\n",
      "(0.013987166479346929, 'lobby')\n",
      "(0.013616447068412182, 'ordinary')\n",
      "(0.013155305374475108, 'premium')\n",
      "(0.013124904898563697, 'the lobby')\n",
      "(0.012757858932937523, 'impolite')\n",
      "(0.012625957983958914, 'your')\n",
      "(0.012577414344585241, 'of my')\n",
      "(0.012573843222988405, 'september')\n",
      "(0.012445173809542499, 'broken')\n",
      "(0.012424031752740154, 'you want')\n",
      "(0.012169451521540883, 'couldn')\n",
      "(0.012157495904193429, 'of soap')\n",
      "(0.012157495904193429, 'bar of')\n",
      "(0.012104981402490431, 'they should')\n",
      "(0.012061211061307319, 'we couldn')\n",
      "(0.01203356638288209, 'my wedding')\n",
      "(0.011443943735576159, 'painted')\n",
      "(0.011422265014394946, 'was slow')\n",
      "(0.011119567514274621, 'he')\n",
      "(0.011017069429409394, 'downtown')\n",
      "(0.01093332330294457, 'shampoo')\n",
      "(0.010687034124596465, 'phone and')\n",
      "(0.010578955646528571, 'want to')\n",
      "(0.010493358468372441, 'two people')\n",
      "(0.010493238209467508, 'excellent and')\n",
      "(0.010453851950825122, 'the cost')\n",
      "(0.010409003288129567, 'just an')\n",
      "(0.010365228830417758, 'the best')\n",
      "(0.010336262904047676, 'this hotel')\n",
      "(0.01027498930697675, 'for two')\n",
      "(0.010098463289144736, 'nicer')\n",
      "(0.010013928803179691, 'best')\n",
      "(0.0099920685876908732, 'an old')\n",
      "(0.0099780909119470979, 'fails')\n",
      "(0.0099201331483655432, 'can')\n",
      "(0.0099072497803116572, 'window')\n",
      "(0.0098421005994785288, 'we were')\n",
      "(0.0098080190210614315, 'hanging')\n",
      "(0.0097308677326312498, 'sleep')\n",
      "(0.0097055781581055177, 'trip there')\n",
      "(0.0097055781581055177, 'seats were')\n",
      "(0.0097055781581055177, 'had even')\n",
      "(0.0097055781581055177, 'goldfish in')\n",
      "(0.0097055781581055177, 'even left')\n",
      "(0.0096865465013621713, 'were')\n",
      "(0.0096571804629870771, 'shocked')\n",
      "(0.0096312987679993828, 'spend your')\n",
      "(0.0096055706097791169, 'the palmer')\n",
      "(0.0096017751302437272, 'disappointing')\n",
      "(0.0095880244436916673, 'slow and')\n",
      "(0.0095728749406287193, 'and thought')\n",
      "(0.0094993524058977381, 'any')\n",
      "(0.009481585908018543, 'up we')\n",
      "(0.0094312001956082404, 'premium price')\n",
      "(0.009369363676114538, 'palmer house')\n",
      "(0.0093513934513874686, 'staying in')\n",
      "(0.0093301597054083543, 'with this')\n",
      "(0.0092825989516846629, 'into the')\n",
      "(0.0092614475295012509, 'palmer')\n",
      "(0.009210409419902206, 'room they')\n",
      "(0.009200920585186961, 'had the')\n",
      "(0.0091839740262250197, 'planning our')\n",
      "(0.0091736236351201862, 'window seats')\n",
      "(0.0091736236351201862, 'recommended this')\n",
      "(0.0091715019195855747, 'and more')\n",
      "(0.0091686861655685611, 'just few')\n",
      "(0.0091686861655685611, 'front door')\n",
      "(0.009157977451914311, 'service was')\n",
      "(0.0091505412059853519, 'definitely recommend')\n",
      "(0.0091343047351609957, 'here')\n",
      "(0.0091050366709714108, 'neighbor')\n",
      "(0.0090588597593874807, 'sofitel')\n",
      "(0.0089552901713911507, 'because we')\n",
      "(0.0088799440582923543, 'there before')\n",
      "(0.0088681866203943818, 'honestly')\n",
      "(0.0088245552191406947, 'old')\n",
      "(0.0087963172439635071, 'major')\n",
      "(0.0087567308011221087, 'of what')\n",
      "(0.0086553111469819186, 'worth')\n",
      "(0.0086499928083182999, 'were already')\n",
      "(0.0086036545538357451, 'bedroom')\n",
      "(0.0085875557773022748, 'the hard')\n",
      "(0.00853021596989143, 'really enjoyed')\n",
      "(0.0085034401949544008, 'seats')\n",
      "(0.0085034401949544008, 'kids were')\n",
      "(0.0085034401949544008, 'happier')\n",
      "(0.0085034401949544008, 'goldfish')\n",
      "(0.0084253359560807657, 'had broken')\n",
      "(0.0084253359560807657, 'full we')\n",
      "(0.0084253359560807657, 'breakfast service')\n",
      "(0.0084253359560807657, 'bottle for')\n",
      "(0.0084205623221835883, 'thought the')\n",
      "(0.0084195277241560715, 'soap')\n",
      "(0.0084011800941943722, 'rollaway')\n",
      "(0.0083706476890781957, 'planning')\n"
     ]
    }
   ],
   "source": [
    "# true positive and false positive features and their importance\n",
    "\n",
    "tp_feat_avg = []\n",
    "fp_feat_avg = []\n",
    "\n",
    "for word, col in index_words.items():\n",
    "    tp_feat_avg.append((tp_averages[0, col]))#, index_words[word]))\n",
    "    fp_feat_avg.append((fp_averages[0, col]))#, index_words[word]))\n",
    "    \n",
    "tp_feat_avg_word = []\n",
    "fp_feat_avg_word = []\n",
    "\n",
    "for i in range(len(tp_feat_avg)):\n",
    "    tp_feat_avg_word.append(list((index_words_list[i], tp_feat_avg[i])))\n",
    "    fp_feat_avg_word.append(list((index_words_list[i], fp_feat_avg[i])))\n",
    "    \n",
    "# sort because this matches the features by index since they are the same vector\n",
    "tp_feat_avg_word.sort()\n",
    "fp_feat_avg_word.sort()\n",
    "\n",
    "\n",
    "# calculate the differences for each feature's importance\n",
    "\n",
    "# empty list\n",
    "feature_differences = []\n",
    "\n",
    "for i in range(len(tp_feat_avg_word)):\n",
    "    difference = fp_feat_avg_word[i][1] - tp_feat_avg_word[i][1]\n",
    "    feature_differences.append((difference, fp_feat_avg_word[i][0]))\n",
    "    \n",
    "# sort descending by feature importance\n",
    "feature_differences.sort(reverse=True)\n",
    "\n",
    "for i in range(100):\n",
    "    print(feature_differences[i])\n",
    "\n",
    "# two resulting series and take the difference of the features. \n",
    "# explain what you did and why you did it\n",
    "# how you could improve it further\n",
    "# how you maintain your model, there is no good answer because language changes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
