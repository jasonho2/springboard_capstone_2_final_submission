{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jho\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# read all individual text reviews to a list of lists then convert to a dataframe\n",
    "\n",
    "# location of folder with reviews\n",
    "filepath = 'C:/Users/jho/Desktop/data_science/op_spam_v1.4'\n",
    "# empty list\n",
    "list_reviews = []\n",
    "\n",
    "# first level\n",
    "negative_or_positive = 'negative_polarity'\n",
    "\n",
    "# 1600 to unpack (1 folder)\n",
    "for polarity in os.listdir(filepath):\n",
    "    # second level\n",
    "    deceptive_or_truthful = 'deceptive_from_MTurk'\n",
    "    # 800 to unpack (2 folders)\n",
    "    for classification in os.listdir(filepath+'/{}'.format(negative_or_positive)):\n",
    "        i = 1\n",
    "        # 400 to unpack (4 folders, or 2 in each subfolder) (third level)\n",
    "        for fold in os.listdir(filepath+'/{}'.format(negative_or_positive)+'/{}'.format(deceptive_or_truthful)):\n",
    "            #80 to unpack (there are 80 reviews in each fold, and there are 5 folds with each of the 4 subfolders) (fourth level)\n",
    "            for file in os.listdir(filepath+'/{}'.format(negative_or_positive)+'/{}'.format(deceptive_or_truthful)+'/fold{}'.format(i)):\n",
    "                # unpack and read (read each file as a review as you unpack all the folders)\n",
    "                with open(filepath+'/{}'.format(negative_or_positive)+'/{}'.format(deceptive_or_truthful)+'/fold{}/'.format(i)+file) as f:\n",
    "                    list_reviews.append([file, f.readline()])\n",
    "                    \n",
    "            i += 1\n",
    "        \n",
    "        # for the folders that have different names than deceptive_from_MTurk in the deceptive/truthful folders\n",
    "        if len(list_reviews) < 401:\n",
    "            deceptive_or_truthful = 'truthful_from_Web'\n",
    "        elif len(list_reviews) > 402:\n",
    "            deceptive_or_truthful = 'truthful_from_TripAdvisor'\n",
    "            \n",
    "    # change the folder for polarity\n",
    "    negative_or_positive = 'positive_polarity'\n",
    "    \n",
    "\n",
    "# create all_reviews_df for list_reviews\n",
    "all_reviews_df = pd.DataFrame(list_reviews, columns=['index', 'review'])\n",
    "\n",
    "\n",
    "# add columns for the classification to the all_reviews_df dataframe. 1 is deceptive/negative and 0 is truthful/positive\n",
    "all_reviews_df.insert(2, 'negative', np.nan)\n",
    "all_reviews_df.insert(3, 'deceptive', np.nan)\n",
    "\n",
    "#print(all_reviews_df)\n",
    "\n",
    "# counter i to iterate over all reviews in all_reviews_df\n",
    "for i in range(0, len(all_reviews_df)):\n",
    "    \n",
    "    # indices 0-799 are negative polarity\n",
    "    if i < 800:\n",
    "        all_reviews_df['negative'].loc[i] = '1'\n",
    "    else:\n",
    "        all_reviews_df['negative'].loc[i] = '0'\n",
    "        \n",
    "    # indices 400-799 are truthful\n",
    "    if 400 <= i < 800:\n",
    "        all_reviews_df['deceptive'].loc[i] = '0'\n",
    "    # indices 1200-1599 are truthful\n",
    "    elif i >= 1200:\n",
    "        all_reviews_df['deceptive'].loc[i] = '0'\n",
    "    # the rest are deceptive\n",
    "    else:\n",
    "        all_reviews_df['deceptive'].loc[i] = '1'\n",
    "        \n",
    "#print(all_reviews_df)\n",
    "\n",
    "# create a dataframe with only the reviews\n",
    "text_only = all_reviews_df['review']\n",
    "\n",
    "#print(text_only.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### for tfidf vectorizer ####\n",
    "\n",
    "# creates tfidf vector / matrix for X and the target y, using original tfidf vector\n",
    "\n",
    "def make_xy(all_reviews_df, tfidf=None):\n",
    "    #Your code here    \n",
    "    if tfidf is None:\n",
    "        tfidf = TfidfVectorizer(min_df=0, ngram_range=(1,2))\n",
    "    X = tfidf.fit_transform(all_reviews_df['review'])\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (all_reviews_df.deceptive == '1').values.astype(np.int)\n",
    "    return X, y, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 1.000000\n",
      "Accuracy on test data:     0.890000\n",
      "\n",
      "[[162  27]\n",
      " [ 17 194]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.86      0.88       189\n",
      "          1       0.88      0.92      0.90       211\n",
      "\n",
      "avg / total       0.89      0.89      0.89       400\n",
      "\n",
      "44\n",
      "\n",
      "356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TFIDF Vectorizer for MultinomialNB and Linear SVM\n",
    "\n",
    "# creates:  x_train: Xtfidf, y_train: ytfidf\n",
    "#           x_test: Xtfidf_test aka the transformed reviews located at the test_index locations, y_test = X_test labels\n",
    "\n",
    "# shuffle split the reviews and test on 400 reviews\n",
    "ss = ShuffleSplit(n_splits=1, test_size=0.25)\n",
    "\n",
    "# splitting the reviews and returning their index from the dataframe\n",
    "for train_index, test_index in ss.split(all_reviews_df['review']):\n",
    "    \n",
    "    #print(\"%s %s\" % (train_index, test_index))\n",
    "    #print(\"%s\" % (test_index))\n",
    "    \n",
    "    # create tfidf vectors from make_xy function using the training indices\n",
    "    Xtfidf, ytfidf, tfidf = make_xy(all_reviews_df.loc[train_index])\n",
    "    \n",
    "    # select classifier. choosing linear svc\n",
    "    clf = LinearSVC()\n",
    "    #clf = svm.SVC(kernel='linear')\n",
    "    #clf = MultinomialNB()\n",
    "    clf_fit = clf.fit(Xtfidf, ytfidf)\n",
    "    # transform the tfidf vector and use as x_test for predictions\n",
    "    Xtfidf_test = tfidf.transform(all_reviews_df['review'][test_index])\n",
    "    prediction = clf_fit.predict(Xtfidf_test)\n",
    "    \n",
    "    #print(prediction)\n",
    "    \n",
    "    #print(all_reviews_df['deceptive'][test_index])\n",
    "    #print(ytfidf[0])\n",
    "\n",
    "    # get the accuracy scores from training and testing sets\n",
    "    training_accuracy = clf.score(Xtfidf, ytfidf)\n",
    "    testing_accuracy = clf.score(Xtfidf_test, all_reviews_df['deceptive'][test_index].astype(np.int))\n",
    "\n",
    "    print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "    print(\"Accuracy on test data:     {:2f}\".format(testing_accuracy))\n",
    "    print('')\n",
    "    \n",
    "    # confusion matrix\n",
    "    print(confusion_matrix(all_reviews_df['deceptive'][test_index].astype(np.int), prediction))\n",
    "    \n",
    "    # classification report\n",
    "    print(classification_report(all_reviews_df['deceptive'][test_index].astype(np.int), prediction))\n",
    "    \n",
    "    ## this prints all of the incorrectly classified reviews\n",
    "\n",
    "    # empty list\n",
    "    wrong_predictions = []\n",
    "\n",
    "    # search where the predicted label is not the same as the label in all_reviews_df\n",
    "    for index in range(len(prediction)):\n",
    "        if all_reviews_df['deceptive'].astype(np.int)[test_index[index]] != prediction[index]:\n",
    "            wrong_predictions.append([all_reviews_df['index'].loc[test_index[index]], all_reviews_df['review'].loc[test_index[index]], all_reviews_df['deceptive'].loc[test_index[index]]])\n",
    "\n",
    "    # convert to dataframe\n",
    "    wrong_predictions = pd.DataFrame(wrong_predictions)\n",
    "    print(len(wrong_predictions))\n",
    "    print('')\n",
    "    \n",
    "    ## this prints all of the correctly classified reviews\n",
    "\n",
    "    # empty list\n",
    "    right_predictions = []\n",
    "\n",
    "    # search where the predicted label is not the same as the label in all_reviews_df\n",
    "    for index in range(len(prediction)):\n",
    "        if all_reviews_df['deceptive'].astype(np.int)[test_index[index]] == prediction[index]:\n",
    "            right_predictions.append([all_reviews_df['index'].loc[test_index[index]], all_reviews_df['review'].loc[test_index[index]], all_reviews_df['deceptive'].loc[test_index[index]]])\n",
    "\n",
    "    # convert to dataframe\n",
    "    right_predictions = pd.DataFrame(right_predictions)\n",
    "    print(len(right_predictions))\n",
    "    print('')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# truthful reviews classified as deceptive\n",
    "false_positives = wrong_predictions[wrong_predictions[2] == '0']\n",
    "#false_positives\n",
    "\n",
    "# deceptive reviews classified as deceptive\n",
    "true_positives = right_predictions[right_predictions[2] == '1']\n",
    "#true_positives\n",
    "len(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the true positive and false positive features from the same tfidf vector\n",
    "\n",
    "# use THE SAME tfidf vector (bi-grams) from make_xy to the true and false positives\n",
    "# the words have the same column indices for tp and fp\n",
    "\n",
    "# create the compressed sparse matrices for true and false positives\n",
    "csr_mat_tp = tfidf.transform(true_positives[1])\n",
    "csr_mat_fp = tfidf.transform(false_positives[1])\n",
    "\n",
    "# average importance for features\n",
    "tp_averages = csr_mat_tp.todense().mean(axis=0)\n",
    "fp_averages = csr_mat_fp.todense().mean(axis=0)\n",
    "\n",
    "# creates dict of all features from the tfidf vector, convert to list\n",
    "index_words = tfidf.vocabulary_\n",
    "index_words_list = list(index_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.016638608110063454, 'affina')\n",
      "(0.015685595024970852, 'parents')\n",
      "(0.01419248444664821, 'they')\n",
      "(0.013486370106030621, 'bit')\n",
      "(0.013167882573083708, 'suite')\n",
      "(0.012870374024907292, 'ambassador')\n",
      "(0.012478956082547591, 'the affina')\n",
      "(0.012447346648152047, 'have to')\n",
      "(0.012262068369042842, 'have')\n",
      "(0.011682623288650896, 'staff')\n",
      "(0.011110185458329747, 'meeting')\n",
      "(0.010950954307954926, 'when my')\n",
      "(0.010528114375181908, 'staff was')\n",
      "(0.010393453507932563, 'great time')\n",
      "(0.010283749764634182, 'new')\n",
      "(0.010197592635930791, 'definitely stay')\n",
      "(0.010072250571404151, 'to')\n",
      "(0.0099656942574563711, 'awesome')\n",
      "(0.009917352751296838, 'meeting rooms')\n",
      "(0.0093214124100248416, 'although')\n",
      "(0.0092564700091256353, 'really')\n",
      "(0.0091863794590830179, 'the biggest')\n",
      "(0.009163825198179789, 'when staying')\n",
      "(0.0091292404387674532, 'me to')\n",
      "(0.0091206022774247084, 'filet mignon')\n",
      "(0.0091206022774247084, 'filet')\n",
      "(0.009111060747031054, 'that for')\n",
      "(0.0089491663065056626, 'feel')\n",
      "(0.0089069797324704148, 'is full')\n",
      "(0.0088084269093682242, 'biggest')\n",
      "(0.0086207097872720764, 'mignon')\n",
      "(0.0085969736914051128, 'that wasn')\n",
      "(0.0085881264548495692, 'above')\n",
      "(0.0084609861713964719, 'east is')\n",
      "(0.008274192956215929, 'here')\n",
      "(0.00820103112621514, 'his')\n",
      "(0.0080721146289616571, 'professional')\n",
      "(0.0080464591309738244, 'bathrooms')\n",
      "(0.0079988919210916536, 'elegance')\n",
      "(0.0079987848856951926, 'wasn')\n",
      "(0.0079649798900984191, 'will definitely')\n",
      "(0.007870367380100312, 'big city')\n",
      "(0.0078346355057826583, 'time here')\n",
      "(0.0078140473131117823, 'such')\n",
      "(0.0077898973294532447, 'cut')\n",
      "(0.0077826731083273587, 'older')\n",
      "(0.0077383183454969636, 'consider')\n",
      "(0.0077047757506537732, 'question')\n",
      "(0.0075781134140292753, 'make you')\n",
      "(0.0075608697270403494, 'towers')\n",
      "(0.0075434662502405153, 'our suite')\n",
      "(0.007542087771662407, 'the ambassador')\n",
      "(0.0075382963620809432, 'found this')\n",
      "(0.0074869976675252135, 'my new')\n",
      "(0.0074129282927625105, 'although not')\n",
      "(0.0073863899483223349, 'single')\n",
      "(0.0073800617037723228, 'should')\n",
      "(0.0072179205972091138, 'bedroom')\n",
      "(0.0072095828481996034, 'but instead')\n",
      "(0.007145793374897489, 'rooms were')\n",
      "(0.0070914154741046984, 'times')\n",
      "(0.007011557773147205, 'conference')\n",
      "(0.0069717195234130242, 'you feel')\n",
      "(0.0069671959165048414, 'clean room')\n",
      "(0.0069053695645548288, 'dried blood')\n",
      "(0.0068433282481424329, 'the concierge')\n",
      "(0.0067988132529989871, 'interview')\n",
      "(0.0067783028450428663, 'east')\n",
      "(0.0067066268096585098, 'was probably')\n",
      "(0.0066862930069575641, 'stay here')\n",
      "(0.0066780839413502803, 'trip advisor')\n",
      "(0.0066780839413502803, 'advisor')\n",
      "(0.0066076781742967477, 'wife and')\n",
      "(0.0065530756692913162, 'card')\n",
      "(0.0065309484044521861, 'us feel')\n",
      "(0.0065225399051887702, 'little')\n",
      "(0.006485137199955966, 'of us')\n",
      "(0.0064662728430253096, 'aren')\n",
      "(0.0064569608478449421, 'exceptional')\n",
      "(0.0064484447402498911, 'this time')\n",
      "(0.0064441979968983447, 'yoga mat')\n",
      "(0.0064441979968983447, 'the yoga')\n",
      "(0.0064441979968983447, 'so easy')\n",
      "(0.0064441979968983447, 'bit steep')\n",
      "(0.0064234203913550395, 'coffee table')\n",
      "(0.0064179571121146606, 'us got')\n",
      "(0.0064179571121146606, 'believe how')\n",
      "(0.0063798359050134552, 'making')\n",
      "(0.006378824851633616, 'that')\n",
      "(0.0063667962176908637, 'wonderful hotel')\n",
      "(0.0062660458649730234, 'full of')\n",
      "(0.0062553569790804462, 'while have')\n",
      "(0.0062553569790804462, 'many chicago')\n",
      "(0.0062553569790804462, 'conveniently situated')\n",
      "(0.0062214310271909625, 'my car')\n",
      "(0.0061617857534925248, 'nervous')\n",
      "(0.0061334631227929421, 'inside')\n",
      "(0.0061284010745398815, 'floor')\n",
      "(0.0061193825878653541, 'they should')\n",
      "(0.0061040092975665292, 'that the')\n"
     ]
    }
   ],
   "source": [
    "# true positive and false positive features and their importance\n",
    "\n",
    "tp_feat_avg = []\n",
    "fp_feat_avg = []\n",
    "\n",
    "for word, col in index_words.items():\n",
    "    tp_feat_avg.append((tp_averages[0, col]))#, index_words[word]))\n",
    "    fp_feat_avg.append((fp_averages[0, col]))#, index_words[word]))\n",
    "    \n",
    "tp_feat_avg_word = []\n",
    "fp_feat_avg_word = []\n",
    "\n",
    "for i in range(len(tp_feat_avg)):\n",
    "    tp_feat_avg_word.append(list((index_words_list[i], tp_feat_avg[i])))\n",
    "    fp_feat_avg_word.append(list((index_words_list[i], fp_feat_avg[i])))\n",
    "    \n",
    "# sort because this matches the features by index since they are the same vector\n",
    "tp_feat_avg_word.sort()\n",
    "fp_feat_avg_word.sort()\n",
    "\n",
    "\n",
    "# calculate the differences for each feature's importance\n",
    "\n",
    "# empty list\n",
    "feature_differences = []\n",
    "\n",
    "for i in range(len(tp_feat_avg_word)):\n",
    "    difference = fp_feat_avg_word[i][1] - tp_feat_avg_word[i][1]\n",
    "    feature_differences.append((difference, fp_feat_avg_word[i][0]))\n",
    "    \n",
    "# sort descending by feature importance\n",
    "feature_differences.sort(reverse=True)\n",
    "\n",
    "for i in range(100):\n",
    "    print(feature_differences[i])\n",
    "\n",
    "# two resulting series and take the difference of the features. \n",
    "# explain what you did and why you did it\n",
    "# how you could improve it further\n",
    "# how you maintain your model, there is no good answer because language changes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
